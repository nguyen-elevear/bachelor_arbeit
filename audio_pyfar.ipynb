{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sounddevice as sd\n",
    "import ipywidgets as widgets\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from scipy.signal import butter, lfilter, iirpeak, iirnotch\n",
    "from scipy.io import wavfile\n",
    "from scipy.fft import fft\n",
    "from scipy.signal import freqz\n",
    "from IPython.display import display, HTML\n",
    "import pyfar as pf\n",
    "from functools import partial\n",
    "import math\n",
    "import soundfile as sf\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import audio ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio = {}\n",
    "#audio[\"airplane_overhead\"] = pf.io.read_audio(\"./airplane_overhead.wav\")\n",
    "#audio[\"coffee_shop\"] = pf.io.read_audio(\"./coffee_shop.wav\")\n",
    "#audio[\"heavy_traffic\"] = pf.io.read_audio(\"./heavy_traffic.wav\")\n",
    "# audio[\"jet_engines\"] = pf.io.read_audio(\"./jet_engines.mp3\")\n",
    "#audio[\"wind_tonal\"] = pf.io.read_audio(\"./wind_tonal.wav\")\n",
    "#audio[\"rumble\"] = pf.io.read_audio(\"./rumble.wav\")\n",
    "# audio[\"wind_tonal2\"] = pf.io.read_audio(\"./wind_tonal2.wav\")\n",
    "# audio[\"thunder\"] = pf.io.read_audio(\"./thunder.wav\")\n",
    "# audio[\"coffee_shop\"] = pf.io.read_audio(\"./coffee_shop.wav\")\n",
    "# audio[\"pink_noise\"] = pf.io.read_audio(\"./pink_noise.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Audio Player Widgets ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Play audio\n",
    "def play_audio(audio, sample_rate):\n",
    "    sd.play(audio.time.T, sample_rate)\n",
    "\n",
    "\n",
    "# Stop audio\n",
    "def stop_audio(b):\n",
    "    sd.stop()\n",
    "\n",
    "\n",
    "\n",
    "def create_play_button(description, signal):\n",
    "    button = widgets.Button(description=description)\n",
    "    button.layout = widgets.Layout(border='1px solid black', border_radius='10px')\n",
    "    button.on_click(lambda b, audio=signal: play_audio(audio, audio.sampling_rate))\n",
    "    button.layout.width = '250px'\n",
    "    return button\n",
    "\n",
    "stop_button = widgets.Button(description=\"Stop Audio\")\n",
    "stop_button.layout = widgets.Layout(border='1px solid black', border_radius='10px')\n",
    "stop_button.on_click(stop_audio)\n",
    "\n",
    "print(sd.query_devices())\n",
    "\n",
    "# Custom CSS to style the ipywidget buttons\n",
    "custom_css = \"\"\"\n",
    "<style>\n",
    "    .jupyter-widgets button {\n",
    "        background-color: white !important;\n",
    "        border: 1px solid black !important;\n",
    "        border-radius: 10px !important;\n",
    "        margin: 10px;\n",
    "    }\n",
    "    .widget-container {\n",
    "        display: flex;\n",
    "        flex-direction: row;\n",
    "        justify-content: start;\n",
    "        align-items: center;\n",
    "    }\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "# Display the custom CSS\n",
    "display(HTML(custom_css))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Filters ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get a FilterIIR Object representing the butterworth filter\"\"\"\n",
    "def get_butterworth(signal, order, cutoff, sample_rate, btype='lowpass'):\n",
    "    return pf.dsp.filter.butterworth(signal, order, cutoff, btype, sample_rate)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Get a FilterIIR Object representing the bell filter\"\"\"\n",
    "def get_bell(signal, center_freq, gain, bandwidth, sample_rate):\n",
    "    return pf.dsp.filter.bell(signal, center_freq, gain, center_freq/bandwidth, sampling_rate=sample_rate)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Get a high shelve filter \"\"\"\n",
    "def get_high_shelve(signal, frequency, frequency_type, gain=-20, bandwidth=5, sampling_rate=44100):\n",
    "    return pf.dsp.filter.high_shelve_cascade(signal, frequency, frequency_type=frequency_type, gain=gain, bandwidth=bandwidth, sampling_rate=sampling_rate)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Get a low shelve filter \"\"\"\n",
    "def get_low_shelve(signal, frequency, frequency_type, gain=-20, bandwidth=5, sampling_rate=44100):\n",
    "    return pf.dsp.filter.low_shelve_cascade(signal, frequency, frequency_type=frequency_type, gain=gain, bandwidth=bandwidth, sampling_rate=sampling_rate)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Apply passive filter \"\"\"\n",
    "def apply_passive_filter(signal):\n",
    "    # Passive curve #\n",
    "    signal = get_high_shelve(signal, 100, 'lower', gain=-20, bandwidth=3.322, sampling_rate=None)[0]\n",
    "    signal = get_high_shelve(signal, 1000, 'lower', gain=-21, bandwidth=1, sampling_rate=None)[0]\n",
    "    signal = get_bell(signal, 10000, 20, 500, sample_rate=None)\n",
    "    signal = get_bell(signal, 4000, 15, 500, sample_rate=None)\n",
    "    signal = get_bell(signal, 300, 15, 100, sample_rate=None)\n",
    "    return signal\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Apply active filter\"\"\"\n",
    "def apply_active_filter(signal):\n",
    "    # Active curve # \n",
    "    signal = get_low_shelve(signal,  15, 'lower', gain=5, bandwidth=1, sampling_rate=None)[0]\n",
    "    signal = get_high_shelve(signal, 30, 'lower', gain=-45, bandwidth=1, sampling_rate=None)[0]\n",
    "    signal = get_high_shelve(signal, 100, 'lower', gain=45, bandwidth=3, sampling_rate=None)[0]\n",
    "    signal = get_bell(signal, 900, 5, 100, sample_rate=None)\n",
    "    signal = get_bell(signal, 3500, 10, 500, sample_rate=None)\n",
    "    signal = get_bell(signal, 2000, -5, 500, sample_rate=None)\n",
    "    signal = get_bell(signal, 300, 10, 500, sample_rate=None)\n",
    "    return signal\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Create Active Filter Simulator\"\"\"\n",
    "def active_filter_simulator(signal, f_cut, f_peak, f_ret, max_gain, starting_gain, sampling_rate=None, reduce=False):\n",
    "    if signal is None:\n",
    "        filter1 = pf.dsp.filter.low_shelve_cascade(signal, f_cut, frequency_type='lower', gain=starting_gain, bandwidth=1, sampling_rate=sampling_rate)[0]\n",
    "        filter2 = pf.dsp.filter.high_shelve_cascade(signal, f_cut, frequency_type='lower', gain=(max_gain-starting_gain), bandwidth=math.log(f_peak/f_cut, 2), sampling_rate=sampling_rate)[0]\n",
    "        filter3 = pf.dsp.filter.high_shelve_cascade(signal, f_peak, frequency_type='lower', gain=(2*starting_gain-max_gain), bandwidth=math.log(f_ret/f_peak, 2), sampling_rate=sampling_rate)[0]\n",
    "        return [filter1, filter2, filter3]\n",
    "    else:\n",
    "        if reduce:\n",
    "            signal = pf.dsp.filter.low_shelve_cascade(signal, f_cut, frequency_type='lower', gain=starting_gain*0.9, bandwidth=1)[0]\n",
    "            signal = pf.dsp.filter.high_shelve_cascade(signal, f_cut, frequency_type='lower', gain=(max_gain-starting_gain)*0.9, bandwidth=math.log(f_peak/f_cut, 2))[0]\n",
    "            signal = pf.dsp.filter.high_shelve_cascade(signal, f_peak, frequency_type='lower', gain=(2*starting_gain-max_gain)*0.9, bandwidth=math.log(f_ret/f_peak, 2))[0]\n",
    "        else:\n",
    "            signal = pf.dsp.filter.low_shelve_cascade(signal, f_cut, frequency_type='lower', gain=starting_gain, bandwidth=1)[0]\n",
    "            signal = pf.dsp.filter.high_shelve_cascade(signal, f_cut, frequency_type='lower', gain=(max_gain-starting_gain), bandwidth=math.log(f_peak/f_cut, 2))[0]\n",
    "            signal = pf.dsp.filter.high_shelve_cascade(signal, f_peak, frequency_type='lower', gain=(2*starting_gain-max_gain), bandwidth=math.log(f_ret/f_peak, 2))[0]\n",
    "        return signal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Plotting Functions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Define custom formatter for axis ticks\"\"\"\n",
    "def custom_formatter(x, pos):\n",
    "    if int(x) >= 1000:\n",
    "        return f'{int(x/1000)}k'\n",
    "    else:\n",
    "        return f'{int(x)}'\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "Define function to plot magnitude spectrum (SPL) of signals\n",
    "    @nrows: number of signals\n",
    "    @ncolumns: number of channels pro signal\n",
    "    @data: a dictionary in form of {signal_type}:{data}\n",
    "\n",
    "\"\"\"\n",
    "def plot_freq(nrows, ncolumns, data, fig=None, ax=None):\n",
    "    if fig is None and ax is None:\n",
    "        fig, ax = plt.subplots(nrows, ncolumns, figsize=(15, 15))\n",
    "    row = 0\n",
    "    column = 0\n",
    "    ticks = [10, 20, 40, 60, 100, 200, 400, 600, 1000, 2000, 4000, 6000, 10000, 20000]\n",
    "    for type, signal in data.items():\n",
    "        if signal.signal_type == \"energy\":\n",
    "            magnitude = 20 * np.log10(abs(signal.freq))\n",
    "        else: \n",
    "            magnitude = 10 * np.log10(abs(signal.freq))    \n",
    "        for channel in range(0, signal.cshape[0]):\n",
    "            ax[row, column].plot(signal.frequencies, magnitude[channel, :], label=f'{type} - Channel {channel}')\n",
    "            ax[row, column].set_xscale(\"log\")\n",
    "            ax[row, column].get_xaxis().set_major_formatter(FuncFormatter(custom_formatter))\n",
    "            ax[row, column].set_xlabel(\"Frequencies [Hz]\")\n",
    "            ax[row, column].set_xticks(ticks)\n",
    "            ax[row, column].set_xlim(10, 20000)\n",
    "            ax[row, column].set_ylabel(\"Magnitude [dB SPL]\")\n",
    "            ax[row, column].legend()\n",
    "            ax[row, column].grid()\n",
    "            column += 1\n",
    "        row += 1\n",
    "        column = 0\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Plot Filter magnitude spectrum\"\"\"\n",
    "def plot_impulse_response(filters, descriptors=None):\n",
    "    impulse = pf.signals.impulse(2**21)\n",
    "    fig, ax = plt.subplots(figsize=(15,5))\n",
    "    for index, filter in enumerate(filters):\n",
    "        impulse_response = filter.process(impulse)\n",
    "        if impulse_response.signal_type == \"energy\":\n",
    "            magnitude = 20 * np.log10(abs(impulse_response.freq))\n",
    "        else: \n",
    "            magnitude = 10 * np.log10(abs(impulse_response.freq))\n",
    "        ax.plot(impulse_response.frequencies, magnitude[0], label=f'{descriptors[index]}')\n",
    "    ticks = [10, 20, 40, 60, 100, 200, 400, 600, 1000, 2000, 4000, 6000, 10000, 20000]\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.get_xaxis().set_major_formatter(FuncFormatter(custom_formatter))\n",
    "    ax.set_xlabel(\"Frequencies [Hz]\")\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_xlim(10, 20000)\n",
    "    ax.set_ylabel(\"Magnitude [dB]\")\n",
    "    ax.set_ylim(-50, 0)\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    return ax, fig\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Plot impulse response cascade\"\"\"\n",
    "def plot_impulse_response_cascade(cascade_filters, descriptors=None, fig=None, ax=None):\n",
    "    impulse_response = pf.signals.impulse(2**21)\n",
    "    if fig is None and ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(15,5))\n",
    "    for index, filters in enumerate(cascade_filters):\n",
    "        for filter in filters:\n",
    "            impulse_response = filter.process(impulse_response)\n",
    "        if impulse_response.signal_type == \"energy\":\n",
    "            magnitude = 20 * np.log10(abs(impulse_response.freq))\n",
    "        else: \n",
    "            magnitude = 10 * np.log10(abs(impulse_response.freq))\n",
    "        ax.plot(impulse_response.frequencies, magnitude[0], label=f'{descriptors[index]}')\n",
    "        impulse_response = pf.signals.impulse(2**21)\n",
    "    ticks = [10, 20, 40, 60, 100, 200, 400, 600, 1000, 2000, 4000, 6000, 10000, 20000]\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.get_xaxis().set_major_formatter(FuncFormatter(custom_formatter))\n",
    "    ax.set_xlabel(\"Frequencies [Hz]\")\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_xlim(1, 20000)\n",
    "    ax.set_ylabel(\"Magnitude [dB]\")\n",
    "    ax.set_ylim(-50, 20)\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Audio Signals ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_freq(len(audio.keys()), 2, audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Butterworth Bandstop Magnitude Spectrum ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bandstops = []\n",
    "# bandstops_descriptors = []\n",
    "# for i in range(1,10):\n",
    "#     bandstops.append(get_butterworth(None, i, [100, 1000], sample_rate=44100, btype='bandstop'))\n",
    "#     bandstops_descriptors.append(f\"{i}-Order\")\n",
    "# plot_impulse_response(bandstops, bandstops_descriptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate ANC Curve ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passive curve #\n",
    "\n",
    "high_shelve1 = get_high_shelve(None, 100, 'lower', sampling_rate=44100, gain=-20, bandwidth=3.322)\n",
    "high_shelve2 = get_high_shelve(None, 1000, 'lower', sampling_rate=44100, gain=-21, bandwidth=1)\n",
    "passive_bell1 = get_bell(None, 10000, 20, 500, sample_rate=44100)\n",
    "passive_bell2 = get_bell(None, 4000, 15, 500, sample_rate=44100)\n",
    "passive_bell3 = get_bell(None, 300, 15, 100, sample_rate=44100)\n",
    "\n",
    "# Active curve # \n",
    "low_shelve1 = get_low_shelve(None,  15, 'lower', gain=5, bandwidth=1, sampling_rate=44100)\n",
    "high_shelve3 = get_high_shelve(None, 30, 'lower', sampling_rate=44100, gain=-45, bandwidth=1)\n",
    "high_shelve4 = get_high_shelve(None, 100, 'lower', sampling_rate=44100, gain=45, bandwidth=3)\n",
    "active_bell1 = get_bell(None, 900, 5, 100, sample_rate=44100)\n",
    "active_bell2 = get_bell(None, 3500, 10, 500, sample_rate=44100)\n",
    "active_bell3 = get_bell(None, 2000, -5, 500, sample_rate=44100)\n",
    "active_bell4 = get_bell(None, 300, 10, 500, sample_rate=44100)\n",
    "\n",
    "\n",
    "plot_impulse_response_cascade([[high_shelve1[0], high_shelve2[0], passive_bell1, passive_bell2, passive_bell3],\n",
    "                               [low_shelve1[0], high_shelve3[0], high_shelve4[0], active_bell1, active_bell2, active_bell3, active_bell4], \n",
    "                               [high_shelve1[0], high_shelve2[0], passive_bell1, passive_bell2, passive_bell3, low_shelve1[0], high_shelve3[0], high_shelve4[0], active_bell1, active_bell2, active_bell3, active_bell4]], ['Passive', 'Active', 'Active + Passive'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Active Curve ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_filters = []\n",
    "# active_descriptors = []\n",
    "# f_tests = [[5, 50, 500], [5, 50, 3500], [15, 250, 1000], [15, 250, 7000], [100, 500, 2000], [100, 500, 7000]]\n",
    "# for index, f_test in enumerate(f_tests):\n",
    "#     active_filters.append(active_filter_simulator(None, f_test[0], f_test[1], f_test[2], -40, 5, 44100))\n",
    "#     active_descriptors.append(f\"f_start={f_test[0]}, f_peak={f_test[1]}, f_ret={f_test[2]}\")\n",
    "\n",
    "# plot_impulse_response_cascade(active_filters, active_descriptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine different active simulators with passive filter ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_filters = []\n",
    "# test_descriptors = []\n",
    "# for index, f_test in enumerate(f_tests):\n",
    "#     test_filters.append([high_shelve1[0], high_shelve2[0], passive_bell1, passive_bell2, passive_bell3] + active_filter_simulator(None, f_test[0], f_test[1], f_test[2], max_gain=-40, starting_gain=5, sampling_rate=44100))\n",
    "#     test_descriptors.append(f'Active + Passive {index}')\n",
    "# plot_impulse_response_cascade(test_filters, test_descriptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Approximating Filter to Different Sounds and Plot the resulting spectrum ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_passive = {}\n",
    "# audio_tot_demo = {}\n",
    "# for type, signal in audio.items():\n",
    "#     signal_passive = apply_passive_filter(signal)\n",
    "#     audio_passive[f'{type}'] = signal_passive\n",
    "#     signal_tot = apply_active_filter(signal_passive)\n",
    "#     audio_tot_demo[f'{type}'] = signal_tot\n",
    "\n",
    "# fig, ax = plot_freq(len(audio.keys()), 2, audio)\n",
    "\n",
    "# fig, ax = plot_freq(len(audio_passive.keys()), 2, audio_passive, fig=fig, ax=ax)\n",
    "\n",
    "# fig, ax = plot_freq(len(audio_tot_demo.keys()), 2, audio_tot_demo, fig=fig, ax=ax)\n",
    "\n",
    "# audio_tot = {}\n",
    "# audio_tot_onesided_none = {}\n",
    "# audio_tot_onesided_50 = {}\n",
    "# for type, signal in audio_passive.items():\n",
    "#     for f_test in f_tests:\n",
    "#         signal_tot = active_filter_simulator(signal, f_test[0], f_test[1], f_test[2], -40, 5)\n",
    "#         signal_tot_50 = active_filter_simulator(signal, f_test[0], f_test[1], f_test[2], -40, 5, reduce=True)\n",
    "#         audio_tot[f\"{type}_{f_test[0]}_{f_test[1]}_{f_test[2]}\"] = signal_tot\n",
    "\n",
    "#         signal_tot_oneside_none = signal_tot\n",
    "#         signal_tot_oneside_none[0] = signal[0]\n",
    "#         signal_tot_oneside_none[1] = signal_tot[1]\n",
    "#         audio_tot_onesided_none[f\"{type}_{f_test[0]}_{f_test[1]}_{f_test[2]}\"] = signal_tot_oneside_none\n",
    "\n",
    "#         signal_tot_oneside_50 = signal_tot\n",
    "#         signal_tot_oneside_50[0] = signal_tot_50[0]\n",
    "#         signal_tot_oneside_50[1] = signal_tot[1]\n",
    "#         audio_tot_onesided_50[f\"{type}_{f_test[0]}_{f_test[1]}_{f_test[2]}\"] = signal_tot_oneside_50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate original and filtered signals to simulate ANC on/off ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_signals_lp = {}\n",
    "\n",
    "# for type, signal in audio.items():\n",
    "#     original_crop = pf.dsp.time_window(signal, interval=[0, 1, 19, 20], unit='s', crop='window', window='boxcar')\n",
    "#     lowpass_crop = pf.dsp.time_window(audio_butterworth[f'{type}'], interval=[0, 1, 19.5, 20], unit='s', crop='window', window='boxcar')\n",
    "#     combined_signals_lp[f'{type}'] = pf.utils.concatenate_channels((original_crop, lowpass_crop), 1)\n",
    "#     pf.io.write_audio(combined_signals_lp[f'{type}'], filename=f'concatenated_lp_{type}.wav')\n",
    "\n",
    "# combined_signals_bs = {}\n",
    "\n",
    "# for type, signal in audio.items():\n",
    "#     original_crop = pf.dsp.time_window(signal, interval=[0, 1, 19, 20], unit='s', crop='window', window='hann')\n",
    "#     bandstop_crop = pf.dsp.time_window(audio_bandstops[f'{type}'], interval=[0, 1, 19, 20], unit='s', crop='window', window='boxcar')\n",
    "#     combined_signals_bs[f'{type}'] = pf.utils.concatenate_channels((original_crop, bandstop_crop), 1)\n",
    "#     pf.io.write_audio(combined_signals_bs[f'{type}'], filename=f'concatenated_bs_{type}.wav')\n",
    "\n",
    "\n",
    "# combined_active_passive = {}\n",
    "# combined_active_passive_onesided_none = {}\n",
    "# combined_active_passive_onesided_50 = {}\n",
    "# for type, signal in audio.items():\n",
    "#     passive_crop = pf.dsp.time_window(audio_passive[type], interval=[1, 1.5, 10.5, 11], unit='s', crop='window')\n",
    "#     for key, item in audio_tot.items():\n",
    "#         if type in key:\n",
    "#             tot_crop = pf.dsp.time_window(audio_tot[key], interval=[1, 1.5, 10.5, 11], unit='s', crop='window')\n",
    "#             combined_active_passive[key] = pf.utils.concatenate_channels((passive_crop, tot_crop), 1)\n",
    "#             pf.io.write_audio(combined_active_passive[key], filename=f'{key}.wav')\n",
    "\n",
    "#             # tot_crop_onesided = pf.dsp.time_window(audio_tot_onesided[key], interval=[1, 1.5, 10.5, 11], unit='s', crop='window')\n",
    "#             tot_crop_onesided_none = pf.dsp.time_window(audio_tot_onesided_none[key], interval=[1, 1.5, 10.5, 11], unit='s', crop='window')\n",
    "#             combined_active_passive_onesided_none[key] = pf.utils.concatenate_channels((passive_crop, tot_crop_onesided_none), 1)\n",
    "#             pf.io.write_audio(combined_active_passive_onesided_none[key], filename=f'{key}_onesided_left_none.wav')\n",
    "\n",
    "#             tot_crop_onesided_50 = pf.dsp.time_window(audio_tot_onesided_50[key], interval=[1, 1.5, 10.5, 11], unit='s', crop='window')\n",
    "#             combined_active_passive_onesided_50[key] = pf.utils.concatenate_channels((passive_crop, tot_crop_onesided_50), 1)\n",
    "#             pf.io.write_audio(combined_active_passive_onesided_50[key], filename=f'{key}_onesided_left_10.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plot_freq(len(audio_tot_onesided_none.keys()), 2, audio_tot_onesided_none)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 3 active different filters for listening test ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_testing_filter(left_slope, right_slope, starting_gain, max_gain, center_freq, signal=None, mismatch = False):\n",
    "    f_lower = center_freq/(2**abs((max_gain-starting_gain)/left_slope))\n",
    "    if signal is not None:\n",
    "        if mismatch:\n",
    "            signal = pf.dsp.filter.low_shelve_cascade(signal, f_lower, frequency_type='lower', gain=starting_gain*0.8, bandwidth=1)[0]\n",
    "            signal = pf.dsp.filter.high_shelve_cascade(signal, f_lower, frequency_type='lower', gain=(max_gain-starting_gain)*0.8, slope=left_slope)[0]\n",
    "            signal = pf.dsp.filter.high_shelve_cascade(signal, center_freq, frequency_type='lower', gain=(2*starting_gain-max_gain)*0.8, slope=right_slope)[0]         \n",
    "            return signal\n",
    "        else:\n",
    "            signal = pf.dsp.filter.low_shelve_cascade(signal, f_lower, frequency_type='lower', gain=starting_gain, bandwidth=1)[0]\n",
    "            signal = pf.dsp.filter.high_shelve_cascade(signal, f_lower, frequency_type='lower', gain=(max_gain-starting_gain), slope=left_slope)[0]\n",
    "            signal = pf.dsp.filter.high_shelve_cascade(signal, center_freq, frequency_type='lower', gain=(2*starting_gain-max_gain), slope=right_slope)[0]\n",
    "            return signal\n",
    "    else: \n",
    "        filter1 = pf.dsp.filter.low_shelve_cascade(signal, f_lower, frequency_type='lower', gain=starting_gain, bandwidth=1, sampling_rate=44100)[0]\n",
    "        filter2 = pf.dsp.filter.high_shelve_cascade(signal, f_lower, frequency_type='lower', gain=(max_gain-starting_gain), slope=left_slope, sampling_rate=44100)[0]\n",
    "        filter3 = pf.dsp.filter.high_shelve_cascade(signal, center_freq, frequency_type='lower', gain=(2*starting_gain-max_gain), slope=right_slope, sampling_rate=44100)[0]\n",
    "\n",
    "        return [filter1, filter2, filter3]\n",
    "\n",
    "\n",
    "testing_filters = []\n",
    "testing_descriptors = []\n",
    "testing_freq = [65, 260, 1040]\n",
    "\n",
    "for freq in testing_freq:\n",
    "    testing_filters.append(create_testing_filter(-11, 25, 0, -40, freq))\n",
    "    testing_descriptors.append(f\"center_freq: {freq} Hz\")\n",
    "\n",
    "plot_impulse_response_cascade(testing_filters, testing_descriptors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Active + Passive curve ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for filters in testing_filters:\n",
    "    filters += [high_shelve1[0], high_shelve2[0], passive_bell1, passive_bell2, passive_bell3]\n",
    "\n",
    "testing_filters.append([high_shelve1[0], high_shelve2[0], passive_bell1, passive_bell2, passive_bell3])\n",
    "testing_descriptors.append(\"passive\")\n",
    "plot_impulse_response_cascade(testing_filters, testing_descriptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create testing sets ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = {}\n",
    "audio[\"public\"] = pf.io.read_audio(\"./test_set/public_-27.wav\")\n",
    "audio[\"airplane\"] = pf.io.read_audio(\"./test_set/airplane_-27.wav\")\n",
    "audio[\"train\"] = pf.io.read_audio(\"./test_set/train_-27.wav\")\n",
    "audio[\"nature_creek\"] = pf.io.read_audio(\"./test_set/nature_creek_-27.wav\")\n",
    "audio[\"midsize_car\"] = pf.io.read_audio(\"./test_set/car_-27.wav\")\n",
    "audio[\"sine_white\"] = pf.io.read_audio(\"./test_set/sine_-27.wav\")\n",
    "audio[\"open_field\"] = pf.io.read_audio(\"/Users/nptlinh/Desktop/BA-Code/test_set/open_field_-27.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_passive = {}\n",
    "audio_tot = {}\n",
    "audio_tot_mismatch = {}\n",
    "for type, signal in audio.items():\n",
    "    signal_passive = apply_passive_filter(signal)\n",
    "    audio_passive[f'{type}'] = signal_passive\n",
    "    passive_crop = pf.dsp.time_window(signal_passive, interval=[0, 0.25, 9.75, 10], unit='s', crop='window')\n",
    "    # pf.io.write_audio(passive_crop, filename=f'./test_set/{type}_passive.wav', subtype=\"FLOAT\")\n",
    "    \n",
    "    # for freq in testing_freq:\n",
    "    #     signal_tot = create_testing_filter(-11, 25, 0, -40, freq, signal_passive, False)\n",
    "    #     signal_mismatch = create_testing_filter(-11, 25, 0, -40, freq, signal_passive, True)\n",
    "    #     audio_tot[f'{type}_{freq}'] = signal_tot\n",
    "\n",
    "    #     signal_tot_mismatch = signal_tot\n",
    "    #     signal_tot_mismatch[0] = signal_mismatch[0]\n",
    "    #     signal_tot_mismatch[1] = signal_tot[1]\n",
    "    #     audio_tot_mismatch[f'{type}_{freq}'] = signal_tot_mismatch\n",
    "\n",
    "    #     tot_crop_mismatch = pf.dsp.time_window(signal_tot_mismatch, interval=[0, 0.25, 9.75, 10], unit='s', crop='window')\n",
    "    #     tot_crop = pf.dsp.time_window(signal_tot, interval=[0, 0.25, 9.75, 10], unit='s', crop='window')\n",
    "    #     pf.io.write_audio(tot_crop, filename=f'./test_set/{type}_{freq}_tot.wav', subtype=\"FLOAT\")\n",
    "    #     pf.io.write_audio(tot_crop_mismatch, filename=f'./test_set/{type}_{freq}_tot_mismatch.wav', subtype=\"FLOAT\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# audio_tot_260 = {type: audio for type, audio in audio_tot_mismatch.items() if \"260\" in type}\n",
    "# audio_tot_65 = {type: audio for type, audio in audio_tot_mismatch.items() if \"65\" in type}\n",
    "# audio_tot_1040 = {type: audio for type, audio in audio_tot_mismatch.items() if \"1040\" in type}\n",
    "\n",
    "    \n",
    "# fig, ax = plot_freq(len(audio_tot_65.keys()), 2, audio_tot_65)\n",
    "\n",
    "# fig, ax = plot_freq(len(audio_tot_260.keys()), 2, audio_tot_260, fig=fig, ax=ax)\n",
    "\n",
    "# fig, ax = plot_freq(len(audio_tot_1040.keys()), 2, audio_tot_1040, fig=fig, ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plot of results ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gui_qt.plot_box import plot_box\n",
    "\n",
    "results = [\"/Users/nptlinh/Desktop/BA-Code/gui_qt/results/filter_pos/airplane.csv\",\n",
    "           \"/Users/nptlinh/Desktop/BA-Code/gui_qt/results/filter_pos/car.csv\",\n",
    "           \"/Users/nptlinh/Desktop/BA-Code/gui_qt/results/filter_pos/train.csv\",\n",
    "           \"/Users/nptlinh/Desktop/BA-Code/gui_qt/results/filter_pos/sine.csv\",\n",
    "           \"/Users/nptlinh/Desktop/BA-Code/gui_qt/results/filter_pos/nature_creek.csv\",\n",
    "           \"/Users/nptlinh/Desktop/BA-Code/gui_qt/results/filter_pos/public.csv\"]\n",
    "plot_box(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_filters = []\n",
    "testing_descriptors = []\n",
    "testing_gains = [-20, -40, -80]\n",
    "bandwidth_left = 4.7\n",
    "bandwidth_right = 2\n",
    "\n",
    "for gain in testing_gains:\n",
    "    left_slope = gain/bandwidth_left\n",
    "    right_slope = -gain/bandwidth_right\n",
    "    testing_filters.append(create_testing_filter(left_slope, right_slope, 0, gain, 300))\n",
    "    testing_descriptors.append(f\"gain: {gain} dB, right slope: {right_slope} dB/Octave, left slope: {left_slope} dB/Octave\")\n",
    "\n",
    "plot_impulse_response_cascade(testing_filters, testing_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = []\n",
    "for index, filters in enumerate(testing_filters):\n",
    "    filters += [high_shelve1[0], high_shelve2[0], passive_bell1, passive_bell2, passive_bell3]\n",
    "    descriptors.append(f\"Passive + Active, gain:{testing_gains[index]}\")\n",
    "    \n",
    "testing_filters.append([high_shelve1[0], high_shelve2[0], passive_bell1, passive_bell2, passive_bell3])\n",
    "descriptors.append(\"passive\")\n",
    "plot_impulse_response_cascade(testing_filters, descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_abrupt = {}\n",
    "audio_filtered = {}\n",
    "audio_crossfade_fast = {}\n",
    "audio_crossfade_slow = {}\n",
    "\n",
    "for type, signal in audio_passive.items():\n",
    "    crop_passive = pf.dsp.time_window(signal, interval=[9.4975, 9.5, 11.5, 11.5025], unit=\"s\", crop=\"window\")\n",
    "    pf.io.write_audio(crop_passive, filename=f\"passive_{type}.wav\", subtype=\"FLOAT\")\n",
    "    for gain in testing_gains:\n",
    "        signal_crop = pf.dsp.time_window(signal, interval=[0, 20], window=\"boxcar\", unit=\"s\", crop=\"window\")\n",
    "        signal_crop_half_1 = pf.dsp.time_window(signal, interval=[0, 10], window=\"boxcar\", unit='s', crop='window') \n",
    "        signal_crop_half_2 = pf.dsp.time_window(signal, interval=[10, 20], window=\"boxcar\", unit=\"s\", crop=\"window\")\n",
    "        filtered_signal = create_testing_filter(gain/bandwidth_left, -gain/bandwidth_right, 0, gain, 300, signal_crop_half_2, False)\n",
    "        audio_filtered[f\"{type}_{gain}\"] = filtered_signal\n",
    "        \n",
    "        fadein_abrupt = pf.dsp.time_window(filtered_signal, interval=[0, 0.01], shape=\"left\", unit=\"s\")\n",
    "        fadein_abrupt = pf.dsp.pad_zeros(fadein_abrupt, fadein_abrupt.sampling_rate*10, mode=\"beginning\")\n",
    "        fadeout_abrupt = pf.dsp.time_window(signal_crop, interval=[10, 10.01], shape=\"right\", unit=\"s\")\n",
    "        combine_fast = fadeout_abrupt + fadein_abrupt\n",
    "        combine_fast = pf.dsp.time_window(combine_fast, interval=[9.4975, 9.5, 12.5, 12.5025], unit=\"s\", crop=\"window\")\n",
    "        audio_abrupt[f\"{type}_{gain}\"] = combine_fast\n",
    "        pf.io.write_audio(combine_fast, filename=f\"abrupt_{type}_{gain}dB.wav\", subtype=\"FLOAT\")\n",
    "\n",
    "        fadein_slow = pf.dsp.time_window(filtered_signal, interval=[0, 1], shape=\"left\", unit=\"s\")\n",
    "        fadein_slow = pf.dsp.pad_zeros(fadein_slow, fadein_slow.sampling_rate*10, mode=\"beginning\")\n",
    "        fadeout_slow = pf.dsp.time_window(signal_crop, interval=[10, 11], shape=\"right\", unit=\"s\")\n",
    "        combine_slow = fadeout_slow + fadein_slow\n",
    "        combine_slow = pf.dsp.time_window(combine_slow, interval=[9.4975, 9.5, 13, 13.5025], unit=\"s\", crop=\"window\")\n",
    "        audio_crossfade_slow[f\"{type}_{gain}\"] = combine_slow\n",
    "        pf.io.write_audio(combine_slow, filename=f\"slow_{type}_{gain}dB.wav\", subtype=\"FLOAT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for type, signal in audio.items():\n",
    "    plt.figure()\n",
    "    plt.title(type)\n",
    "    plt.plot(signal.time[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_80 = {type: audio for type, audio in audio_filtered.items() if \"80\" in type}\n",
    "fig, ax = plot_freq(len(audio_passive.keys()), 2, audio_passive)\n",
    "\n",
    "plot_freq(len(audio_80.keys()), 2, audio_80 , fig=fig, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Different coloured noise ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize(signal, peak=0.9):\n",
    "#     for channel in range(signal.shape[0]):\n",
    "#         max_amplitude = np.max(np.abs(signal[channel]))\n",
    "#         if max_amplitude != 0:\n",
    "#             signal[channel] /= max_amplitude / peak\n",
    "#     return signal\n",
    "\n",
    "\n",
    "\n",
    "# def psd(duration, sampling_rate, calculate_weight = lambda frequencies: 1):\n",
    "#     samples = int(duration*sampling_rate)\n",
    "\n",
    "#     white_left = np.fft.rfft(np.random.randn(samples))\n",
    "#     white_right = np.fft.rfft(np.random.randn(samples))\n",
    "\n",
    "#     weight_left = calculate_weight(np.fft.rfftfreq(samples, d=1/sampling_rate))\n",
    "#     weight_right = calculate_weight(np.fft.rfftfreq(samples, d=1/sampling_rate))\n",
    "\n",
    "#     # Normalize weight\n",
    "#     weight_left = weight_left / np.sqrt(np.mean(weight_left**2))\n",
    "#     weight_right = weight_right / np.sqrt(np.mean(weight_right**2))\n",
    "\n",
    "#     # Apply weights to the white noise\n",
    "#     left_channel = np.fft.irfft(white_left * weight_left)\n",
    "#     right_channel = np.fft.irfft(white_right * weight_right)\n",
    "\n",
    "#     # Initialize and fill the sound array\n",
    "#     sound = np.zeros((2, samples))\n",
    "#     sound[0, :len(left_channel)] = left_channel\n",
    "#     sound[1, :len(right_channel)] = right_channel\n",
    "\n",
    "#     return sound\n",
    "\n",
    "\n",
    "# def colored_spectrum(func):\n",
    "#     return lambda duration, sampling_rate: psd(duration, sampling_rate, func)\n",
    "\n",
    "# @colored_spectrum\n",
    "# def white_noise(frequencies):\n",
    "#     return 1\n",
    "\n",
    "# @colored_spectrum\n",
    "# def pink_noise(frequencies):\n",
    "#     return 1/np.where(frequencies == 0, float('inf'), np.sqrt(frequencies))\n",
    "\n",
    "# @colored_spectrum\n",
    "# def brown_noise(frequencies):\n",
    "#     return 1/np.where(frequencies == 0, float(\"inf\"), frequencies)\n",
    "\n",
    "# @colored_spectrum\n",
    "# def blue_noise(frequencies):\n",
    "#     return np.sqrt(frequencies)\n",
    "\n",
    "# @colored_spectrum\n",
    "# def violet_noise(frequencies):\n",
    "#     return frequencies\n",
    "\n",
    "\n",
    "# white = normalize(white_noise(30, 44100))\n",
    "# brown = normalize(brown_noise(30, 44100))\n",
    "# pink = normalize(pink_noise(30, 44100))\n",
    "# blue = normalize(blue_noise(30, 44100))\n",
    "# violet = normalize(violet_noise(30, 44100))\n",
    "\n",
    "# print(np.max(brown[0]))\n",
    "# print(np.max(brown[1]))\n",
    "\n",
    "# sf.write(\"./white.wav\", white.T, 44100)\n",
    "# sf.write(\"./pink.wav\", pink.T, 44100)\n",
    "# sf.write(\"./blue.wav\", blue.T, 44100)\n",
    "# sf.write(\"./violet.wav\", violet.T, 44100)\n",
    "\n",
    "low_bias = pf.signals.sine(40, 1323001, (1,1)) + pf.signals.sine(20, 1323001, (1,1)) + pf.signals.sine(60, 1323001, (1,1)) + pf.signals.sine(100, 1323001, (1,1)) + pf.signals.sine(500, 1323001, (1,1)) + pf.signals.sine(300, 1323001, (1,1))\n",
    "high_bias = pf.signals.sine(40, 1323001, (1,1)) + pf.signals.sine(20, 1323001, (1,1)) + pf.signals.sine(500, 1323001, (1,1)) + pf.signals.sine(300, 1323001, (1,1)) + pf.signals.sine(600, 1323001, (1,1)) + pf.signals.sine(700, 1323001, (1,1))\n",
    "\n",
    "pf.io.write_audio(low_bias, \"low_bias.wav\", \"FLOAT\")\n",
    "pf.io.write_audio(high_bias, \"high_bias.wav\", \"FLOAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor_arbeit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
